{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching arXiv for ti%3Amachine%20learning\n"
     ]
    }
   ],
   "source": [
    "base_ulr = \"http://export.arxiv.org/api/query?\"\n",
    "\n",
    "search_query = urllib.parse.quote(\"ti:machine learning\")\n",
    "i = 0\n",
    "results_per_itteration = 1000\n",
    "wait_time = 3\n",
    "\n",
    "papers = []\n",
    "year = \"\"\n",
    "\n",
    "print(\"Searching arXiv for %s\" % search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n",
      "Results 0 - 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (i, results_per_itteration))\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_query=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m&start=\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m&max_results=\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m&sortBy=submittedDate&sortOrder=descending\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (search_query,\n\u001b[1;32m      5\u001b[0m         i, results_per_itteration)\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_ulr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m feed \u001b[38;5;241m=\u001b[39m feedparser\u001b[38;5;241m.\u001b[39mparse(response)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m feed\u001b[38;5;241m.\u001b[39mentries:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readall_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:576\u001b[0m, in \u001b[0;36mHTTPResponse._readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:613\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while (year != \"2022\"):\n",
    "    print(\"Results %i - %i\" % (i, results_per_itteration))\n",
    "    \n",
    "    query = 'search_query=%s&start=%i&max_results=%i&sortBy=submittedDate&sortOrder=descending' % (search_query,\n",
    "            i, results_per_itteration)\n",
    "    \n",
    "    response = urllib.request.urlopen(base_ulr + query).read()\n",
    "    \n",
    "    feed = feedparser.parse(response)\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        paper = {}\n",
    "        paper[\"title\"] = entry.title\n",
    "        paper[\"summar\"] = entry.summary\n",
    "        papers.append(paper)\n",
    "        \n",
    "print(\"Bulk: %i\" % i)\n",
    "i += results_per_itteration\n",
    "time.sleep(wait_time)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60809\n"
     ]
    }
   ],
   "source": [
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective recognition of spatial patterns and learning their hierarchy is\n",
      "crucial in modern spatial data analysis. Volumetric data applications seek\n",
      "techniques ensuring invariance not only to shifts but also to pattern\n",
      "rotations. While traditional methods can readily achieve translational\n",
      "invariance, rotational invariance possesses multiple challenges and remains an\n",
      "active area of research. Here, we present ILPO-Net (Invariant to Local Patterns\n",
      "Orientation Network), a novel approach that handles arbitrarily shaped patterns\n",
      "with the convolutional operation inherently invariant to local spatial pattern\n",
      "orientations using the Wigner matrix expansions. Our architecture seamlessly\n",
      "integrates the new convolution operator and, when benchmarked on diverse\n",
      "volumetric datasets such as MedMNIST and CATH, demonstrates superior\n",
      "performance over the baselines with significantly reduced parameter counts - up\n",
      "to 1000 times fewer in the case of MedMNIST. Beyond these demonstrations,\n",
      "ILPO-Net's rotational invariance paves the way for other applications across\n",
      "multiple disciplines. Our code is publicly available at\n",
      "https://gricad-gitlab.univ-grenoble-alpes.fr/GruLab/ILPONet.\n"
     ]
    }
   ],
   "source": [
    "print(papers[10]['summar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60809/60809 [00:00<00:00, 509770.49it/s]\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "summaries = []\n",
    "\n",
    "for item in tqdm(papers):\n",
    "    title = item['title']\n",
    "    summary = item['summar']\n",
    "    \n",
    "    titles.append(title)\n",
    "    summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = (\"sample.txt\")\n",
    "\n",
    "with open(txt_path, 'w') as file:\n",
    "    for string in summaries:\n",
    "        file.write(string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InterDreamer: Zero-Shot Text to 3D Dynamic Hum...</td>\n",
       "      <td>Text-conditioned human motion generation has e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GraspXL: Generating Grasping Motions for Diver...</td>\n",
       "      <td>Human hands possess the dexterity to interact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human-compatible driving partners through data...</td>\n",
       "      <td>A central challenge for autonomous vehicles is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparse Feature Circuits: Discovering and Editi...</td>\n",
       "      <td>We introduce methods for discovering and apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siamese Vision Transformers are Scalable Audio...</td>\n",
       "      <td>Traditional audio-visual methods rely on indep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  InterDreamer: Zero-Shot Text to 3D Dynamic Hum...   \n",
       "1  GraspXL: Generating Grasping Motions for Diver...   \n",
       "2  Human-compatible driving partners through data...   \n",
       "3  Sparse Feature Circuits: Discovering and Editi...   \n",
       "4  Siamese Vision Transformers are Scalable Audio...   \n",
       "\n",
       "                                              summar  \n",
       "0  Text-conditioned human motion generation has e...  \n",
       "1  Human hands possess the dexterity to interact ...  \n",
       "2  A central challenge for autonomous vehicles is...  \n",
       "3  We introduce methods for discovering and apply...  \n",
       "4  Traditional audio-visual methods rely on indep...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(papers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
