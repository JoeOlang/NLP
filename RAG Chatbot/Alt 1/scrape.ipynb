{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching arXiv for ti%3Amachine%20learning\n"
     ]
    }
   ],
   "source": [
    "base_ulr = \"http://export.arxiv.org/api/query?\"\n",
    "\n",
    "search_query = urllib.parse.quote(\"ti:machine learning\")\n",
    "i = 0\n",
    "results_per_itteration = 1000\n",
    "wait_time = 3\n",
    "\n",
    "papers = []\n",
    "year = \"\"\n",
    "\n",
    "print(\"Searching arXiv for %s\" % search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (year != \"2022\"):\n",
    "    #print(\"Results %i - %i\" % (i, results_per_itteration))\n",
    "    \n",
    "    query = 'search_query=%s&start=%i&max_results=%i&sortBy=submittedDate&sortOrder=descending' % (search_query,\n",
    "            i, results_per_itteration)\n",
    "    \n",
    "    response = urllib.request.urlopen(base_ulr + query).read()\n",
    "    \n",
    "    feed = feedparser.parse(response)\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        paper = {}\n",
    "        paper[\"title\"] = entry.title\n",
    "        paper[\"summar\"] = entry.summary\n",
    "        papers.append(paper)\n",
    "        \n",
    "#print(\"Bulk: %i\" % i)\n",
    "i += results_per_itteration\n",
    "time.sleep(wait_time)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60809\n"
     ]
    }
   ],
   "source": [
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective recognition of spatial patterns and learning their hierarchy is\n",
      "crucial in modern spatial data analysis. Volumetric data applications seek\n",
      "techniques ensuring invariance not only to shifts but also to pattern\n",
      "rotations. While traditional methods can readily achieve translational\n",
      "invariance, rotational invariance possesses multiple challenges and remains an\n",
      "active area of research. Here, we present ILPO-Net (Invariant to Local Patterns\n",
      "Orientation Network), a novel approach that handles arbitrarily shaped patterns\n",
      "with the convolutional operation inherently invariant to local spatial pattern\n",
      "orientations using the Wigner matrix expansions. Our architecture seamlessly\n",
      "integrates the new convolution operator and, when benchmarked on diverse\n",
      "volumetric datasets such as MedMNIST and CATH, demonstrates superior\n",
      "performance over the baselines with significantly reduced parameter counts - up\n",
      "to 1000 times fewer in the case of MedMNIST. Beyond these demonstrations,\n",
      "ILPO-Net's rotational invariance paves the way for other applications across\n",
      "multiple disciplines. Our code is publicly available at\n",
      "https://gricad-gitlab.univ-grenoble-alpes.fr/GruLab/ILPONet.\n"
     ]
    }
   ],
   "source": [
    "print(papers[10]['summar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 988674.67it/s]\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "summaries = []\n",
    "\n",
    "for item in tqdm(papers[:20000]):\n",
    "    title = item['title']\n",
    "    summary = item['summar']\n",
    "    \n",
    "    titles.append(title)\n",
    "    summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = (\"sample2.txt\")\n",
    "\n",
    "with open(txt_path, 'w') as file:\n",
    "    for string in summaries:\n",
    "        file.write(string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InterDreamer: Zero-Shot Text to 3D Dynamic Hum...</td>\n",
       "      <td>Text-conditioned human motion generation has e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GraspXL: Generating Grasping Motions for Diver...</td>\n",
       "      <td>Human hands possess the dexterity to interact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human-compatible driving partners through data...</td>\n",
       "      <td>A central challenge for autonomous vehicles is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparse Feature Circuits: Discovering and Editi...</td>\n",
       "      <td>We introduce methods for discovering and apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siamese Vision Transformers are Scalable Audio...</td>\n",
       "      <td>Traditional audio-visual methods rely on indep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  InterDreamer: Zero-Shot Text to 3D Dynamic Hum...   \n",
       "1  GraspXL: Generating Grasping Motions for Diver...   \n",
       "2  Human-compatible driving partners through data...   \n",
       "3  Sparse Feature Circuits: Discovering and Editi...   \n",
       "4  Siamese Vision Transformers are Scalable Audio...   \n",
       "\n",
       "                                              summar  \n",
       "0  Text-conditioned human motion generation has e...  \n",
       "1  Human hands possess the dexterity to interact ...  \n",
       "2  A central challenge for autonomous vehicles is...  \n",
       "3  We introduce methods for discovering and apply...  \n",
       "4  Traditional audio-visual methods rely on indep...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(papers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
