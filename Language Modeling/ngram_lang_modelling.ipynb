{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e-olang/NLP/blob/main/Language%20Modeling/ngram_lang_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This a brief notebook describing implementation of a language model using n-gram approach. With the rise of modern NLP techniques such as fill mask transfomers, n-gram approache isnt really as popular. However, since it is one of the beuilidng blocks of NLP, I feel its a good starting point alongside other key topics e.g. Bag of words & Embeddings for anyone new to NLP.\n",
        "\n",
        "Will be updating this notebook with a better commeted version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbMNXjRqO2Nb"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "\n",
        "!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "V2o04X5UPBFY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j04j7y4GNSuu"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vXNoly-CJAfl"
      },
      "outputs": [],
      "source": [
        "# Create a placeholder for model\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of co-occurance  \n",
        "for sentence in reuters.sents():\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        " \n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUhI0yEgP0f_",
        "outputId": "ef925e75-582a-4cf2-9188-57e9065e01c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'700': 0.018867924528301886,\n",
              " 'a': 0.24528301886792453,\n",
              " 'about': 0.018867924528301886,\n",
              " 'also': 0.018867924528301886,\n",
              " 'an': 0.03773584905660377,\n",
              " 'approved': 0.018867924528301886,\n",
              " 'available': 0.018867924528301886,\n",
              " 'believed': 0.018867924528301886,\n",
              " 'definitely': 0.018867924528301886,\n",
              " 'done': 0.03773584905660377,\n",
              " 'expected': 0.018867924528301886,\n",
              " 'hardly': 0.03773584905660377,\n",
              " 'most': 0.018867924528301886,\n",
              " 'not': 0.07547169811320754,\n",
              " 'now': 0.018867924528301886,\n",
              " 'partly': 0.018867924528301886,\n",
              " 'possible': 0.018867924528301886,\n",
              " 'probably': 0.018867924528301886,\n",
              " 'still': 0.018867924528301886,\n",
              " 'the': 0.24528301886792453,\n",
              " 'underpinning': 0.018867924528301886,\n",
              " 'unlikely': 0.018867924528301886,\n",
              " 'within': 0.018867924528301886}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(model[\"this\", \"is\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "womv2485QPYv",
        "outputId": "9c254e9c-736e-4e0b-e3cd-2c5881d98ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "today the newspaper quoted Linda Geraldez , an EC official said .\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# some starting words\n",
        "text = [\"today\", \"the\"]\n",
        "is_sent_complete = False\n",
        "\n",
        "while not is_sent_complete:\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        "\n",
        "    for word in model[tuple(text[-2:])].keys():\n",
        "        accumulator += model[tuple(text[-2:])][word]\n",
        "\n",
        "        if accumulator >= r:\n",
        "            text.append(word)\n",
        "            break\n",
        "\n",
        "    if text[-2:] == [None, None]:\n",
        "        is_sent_complete = True\n",
        "\n",
        "print(' '.join([t for t in text if t]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOD63ir2C4Z0uDC4cL0UKPy",
      "include_colab_link": true,
      "mount_file_id": "1ek68_acNO9qZeNNsf9DVYUkLXl1I6_vt",
      "name": "NLG1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
