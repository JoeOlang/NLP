{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/olang/Desktop/*/Projects/NLP/Semantic Search/sampledata/titles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Security Guard Deployment System Using Vehicul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Breast Cancer Detection System using Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autism Spectrum Disorder prediction in childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy consumption prediction and scheduling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Intelligent Chatbot for Finance and Banking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title\n",
       "0  Security Guard Deployment System Using Vehicul...\n",
       "1  A Breast Cancer Detection System using Machine...\n",
       "2  Autism Spectrum Disorder prediction in childre...\n",
       "3   Energy consumption prediction and scheduling ...\n",
       "4     An Intelligent Chatbot for Finance and Banking"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         0\n",
       "Embeddings    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security Guard Deployment System Using Vehicular Movement Behaviour: Case of Residential Real Estates\n",
      " A Breast Cancer Detection System using Machine learning \n"
     ]
    }
   ],
   "source": [
    "# sample sentences\n",
    "\n",
    "x = df.Title.iloc[0]\n",
    "y = df.Title.iloc[1]\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeding for each sentence, using transformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [x, y]\n",
    "\n",
    "# Tokenize sentences\n",
    "sample_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings\n",
    "with torch.no_grad():             # no grad here means no backpropagation i.e. no training\n",
    "    sample_embeddings = model(**sample_input)           # the two ** is to unpack the dictionary\n",
    "\n",
    "# get sentence embeddings, through pefroming mean pooling on token embeddings.\n",
    "# this is the same as the sentence embeddings from the sentence-transformers library\n",
    "sample_sent_embeddings = mean_pooling(sample_embeddings, sample_input['attention_mask'])\n",
    "\n",
    "# normalize embeddings, i.e. make them unit vectors by dividing by their L2 norm. L2 being the euclidean distance\n",
    "sample_sent_embeddings = F.normalize(sample_sent_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence embeddings:\")\n",
    "print(sample_sent_embeddings.shape)\n",
    "#print(sample_sent_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enclode all as a function\n",
    "\n",
    "def get_sentence_emd(sentence_list):\n",
    "    encoded_input = tokenizer(sentence_list, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = get_sentence_emd(df.Title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140, 384])\n"
     ]
    }
   ],
   "source": [
    "print(all_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Security Guard Deployment System Using Vehicul...</td>\n",
       "      <td>[0.0831846296787262, -0.00844046100974083, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Breast Cancer Detection System using Machine...</td>\n",
       "      <td>[-0.005373380612581968, 0.006123208440840244, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autism Spectrum Disorder prediction in childre...</td>\n",
       "      <td>[0.04774220287799835, -0.08992604911327362, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy consumption prediction and scheduling ...</td>\n",
       "      <td>[-0.04396095499396324, 0.02846721187233925, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Intelligent Chatbot for Finance and Banking</td>\n",
       "      <td>[-0.04426628351211548, 0.0009629157721064985, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Security Guard Deployment System Using Vehicul...   \n",
       "1  A Breast Cancer Detection System using Machine...   \n",
       "2  Autism Spectrum Disorder prediction in childre...   \n",
       "3   Energy consumption prediction and scheduling ...   \n",
       "4     An Intelligent Chatbot for Finance and Banking   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [0.0831846296787262, -0.00844046100974083, -0....  \n",
       "1  [-0.005373380612581968, 0.006123208440840244, ...  \n",
       "2  [0.04774220287799835, -0.08992604911327362, 0....  \n",
       "3  [-0.04396095499396324, 0.02846721187233925, 0....  \n",
       "4  [-0.04426628351211548, 0.0009629157721064985, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embeddings'] = all_embeddings.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('titles_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
