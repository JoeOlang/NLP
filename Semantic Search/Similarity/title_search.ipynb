{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/olang/Desktop/*/Projects/NLP/Semantic Search/sampledata/titles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Security Guard Deployment System Using Vehicul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Breast Cancer Detection System using Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autism Spectrum Disorder prediction in childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy consumption prediction and scheduling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Intelligent Chatbot for Finance and Banking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title\n",
       "0  Security Guard Deployment System Using Vehicul...\n",
       "1  A Breast Cancer Detection System using Machine...\n",
       "2  Autism Spectrum Disorder prediction in childre...\n",
       "3   Energy consumption prediction and scheduling ...\n",
       "4     An Intelligent Chatbot for Finance and Banking"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security Guard Deployment System Using Vehicular Movement Behaviour: Case of Residential Real Estates\n",
      " A Breast Cancer Detection System using Machine learning \n"
     ]
    }
   ],
   "source": [
    "# sample sentences\n",
    "\n",
    "x = df.Title.iloc[0]\n",
    "y = df.Title.iloc[1]\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeding for each sentence, using transformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [x, y]\n",
    "\n",
    "# Tokenize sentences\n",
    "sample_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings\n",
    "with torch.no_grad():             # no grad here means no backpropagation i.e. no training\n",
    "    sample_embeddings = model(**sample_input)           # the two ** is to unpack the dictionary\n",
    "\n",
    "# get sentence embeddings, through pefroming mean pooling on token embeddings.\n",
    "# this is the same as the sentence embeddings from the sentence-transformers library\n",
    "sample_sent_embeddings = mean_pooling(sample_embeddings, sample_input['attention_mask'])\n",
    "\n",
    "# normalize embeddings, i.e. make them unit vectors by dividing by their L2 norm. L2 being the euclidean distance\n",
    "sample_sent_embeddings = F.normalize(sample_sent_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence embeddings:\")\n",
    "print(sample_sent_embeddings.shape)\n",
    "#print(sample_sent_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enclode all as a function\n",
    "\n",
    "def get_sentence_emd(sentence_list):\n",
    "    encoded_input = tokenizer(sentence_list, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = get_sentence_emd(df.Title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140, 384])\n"
     ]
    }
   ],
   "source": [
    "print(all_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Security Guard Deployment System Using Vehicul...</td>\n",
       "      <td>[0.0831846296787262, -0.00844046100974083, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Breast Cancer Detection System using Machine...</td>\n",
       "      <td>[-0.005373380612581968, 0.006123208440840244, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autism Spectrum Disorder prediction in childre...</td>\n",
       "      <td>[0.04774220287799835, -0.08992604911327362, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy consumption prediction and scheduling ...</td>\n",
       "      <td>[-0.04396095499396324, 0.02846721187233925, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Intelligent Chatbot for Finance and Banking</td>\n",
       "      <td>[-0.04426628351211548, 0.0009629157721064985, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Security Guard Deployment System Using Vehicul...   \n",
       "1  A Breast Cancer Detection System using Machine...   \n",
       "2  Autism Spectrum Disorder prediction in childre...   \n",
       "3   Energy consumption prediction and scheduling ...   \n",
       "4     An Intelligent Chatbot for Finance and Banking   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [0.0831846296787262, -0.00844046100974083, -0....  \n",
       "1  [-0.005373380612581968, 0.006123208440840244, ...  \n",
       "2  [0.04774220287799835, -0.08992604911327362, 0....  \n",
       "3  [-0.04396095499396324, 0.02846721187233925, 0....  \n",
       "4  [-0.04426628351211548, 0.0009629157721064985, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embeddings'] = all_embeddings.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('titles_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from sklearn.manifold import TSNE       # t-distributed stochastic neighbor embedding (t-SNE) is a technique for dimensionality reduction\\nimport matplotlib.pyplot as plt\\n\\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\\ntsne_results = tsne.fit_transform(all_embeddings)\\n\\ndf[\\'tsne-2d-one\\'] = tsne_results[:,0]\\ndf[\\'tsne-2d-two\\'] = tsne_results[:,1]\\n\\nplt.figure(figsize=(16,10))\\nplt.scatter(\\n    x=df[\"tsne-2d-one\"], y=df[\"tsne-2d-two\"],\\n    c=\\'blue\\',\\n    s=10,\\n    alpha=0.5\\n)\\n\\nplt.show() '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the embeddings in 2D space\n",
    "\n",
    "\"\"\" from sklearn.manifold import TSNE       # t-distributed stochastic neighbor embedding (t-SNE) is a technique for dimensionality reduction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "df['tsne-2d-one'] = tsne_results[:,0]\n",
    "df['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.scatter(\n",
    "    x=df[\"tsne-2d-one\"], y=df[\"tsne-2d-two\"],\n",
    "    c='blue',\n",
    "    s=10,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for similar sentences\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similar_sentences(query, df, top_n=5):\n",
    "    query_embedding = get_sentence_emd([query])\n",
    "    df['similarity'] = cosine_similarity(query_embedding, df['Embeddings'].tolist())[0]\n",
    "    df = df.sort_values(by=['similarity'], ascending=False)[:top_n]\n",
    "    titles = df.Title.tolist()\n",
    "    similarities = df.similarity.tolist()\n",
    "\n",
    "    return titles, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = 'Deep Learning'\n",
    "query = str(input('Enter a query: '))\n",
    "l1, l2 = get_similar_sentences(query, df_bkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017978191375732422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bb340487f249d3ad70e629b0b09148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning\n",
      "Title :  Speech Emotion Recognizer using Deep Learning\n",
      "Similarity :  0.52\n",
      "------------------------------------------------------------------------------------------\n",
      "Deep learning\n",
      "Title :  House Property Price Prediction System Using Deep Learning\n",
      "Similarity :  0.51\n",
      "------------------------------------------------------------------------------------------\n",
      "Deep learning\n",
      "Title :  A pneumonia detection model using deep learning\n",
      "Similarity :  0.48\n",
      "------------------------------------------------------------------------------------------\n",
      "Deep learning\n",
      "Title :  Dysarthric speech analysis and  recognition system using Deep Neural Networks\n",
      "Similarity :  0.46\n",
      "------------------------------------------------------------------------------------------\n",
      "Deep learning\n",
      "Title :  A Deep Learning Model for the Segmentation and Classification of Melanoma Skin Lesions\n",
      "Similarity :  0.45\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for i, j in tqdm(zip(l1, l2)):\n",
    "    print(query)\n",
    "    print(\"Title : \", i)\n",
    "    print(\"Similarity : \", round(j, 2))\n",
    "    print('---------' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def get_similar_sentences(query, df, top_n=5):\n",
    "    query_embedding = get_sentence_emd([query])\n",
    "    df['similarity'] = cosine_similarity(query_embedding, df['Embeddings'].tolist())[0]\n",
    "    df = df.sort_values(by=['similarity'], ascending=False)[:top_n]\n",
    "    titles = df.Title.tolist()\n",
    "    similarities = df.similarity.tolist()\n",
    "\n",
    "    return titles, similarities\n",
    "\n",
    "def get_similar_titles(query):\n",
    "    l1, l2 = get_similar_sentences(query, df_bkp)\n",
    "    return l1, l2\n",
    "\n",
    "title = \"Semantic Search\"\n",
    "description = \"Search for similar titles\"\n",
    "article = gr.inputs.Textbox(lines=5, placeholder=\"Enter a query\")\n",
    "output = gr.outputs.Textbox(type=\"auto\", label=\"Similar Titles\")\n",
    "\n",
    "gr.Interface(get_similar_titles, article, output, title=title, description=description, allow_flagging=False).launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
