{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkffOY96MsywaTEB5t2gMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e-olang/NLP/blob/main/Auto%20Completion/Fine-tuned%20Fill-Mask%20Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers -q"
      ],
      "metadata": {
        "id": "XDa8DTcpktFV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, AdamW, AutoTokenizer, AutoModelForMaskedLM\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "13aFIYtdjEBA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model and tokenizer from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"eolang/SW-v1\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"eolang/SW-v1\")\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc4jubTGjFxV",
        "outputId": "92eafad4-8cf5-420b-b6b1-35cbd28a8410"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VeSzi4xti72_"
      },
      "outputs": [],
      "source": [
        "# Custom dataset for loading your text data\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        for text in texts:\n",
        "            encodings = tokenizer(text, truncation=True, max_length=max_length, padding='max_length')\n",
        "            self.input_ids.append(torch.tensor(encodings['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "# Assume `texts` contains your training sentences.\n",
        "# texts = ['Example sentence 1', 'Example sentence 2', ...]\n",
        "# dataset = TextDataset(texts, tokenizer, max_length=50)\n",
        "# loader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset('swahili')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77GA3FwAkm4L",
        "outputId": "53327d41-a729-4405-99f7-6f6e1614cf6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 42069\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3371\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3372\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr = data['train']['text']\n",
        "ts = data['test']['text']\n",
        "val = data['validation']['text']"
      ],
      "metadata": {
        "id": "HyMWRpxOlA8I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tr + ts + val\n",
        "print(len(texts))\n",
        "\n",
        "dataset = TextDataset(texts, tokenizer, max_length=50)\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMl85dxbki3E",
        "outputId": "35eafd6f-1fc1-420e-bcdd-3db63a6ebc83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training configurations\n",
        "epochs = 1\n",
        "learning_rate = 5e-5\n",
        "warmup_steps = 1e2\n",
        "total_steps = len(loader) * epochs\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgM1ovcgjKiG",
        "outputId": "cab2a04a-e5cf-45b7-cc43-0f5baa40fa3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    for i, (input_ids, attn_masks) in enumerate(loader):\n",
        "        input_ids = input_ids.to(device)\n",
        "        attn_masks = attn_masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attn_masks, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLtKE55-jLOK",
        "outputId": "d01ddadd-9bff-4a19-b4d0-aa66c4b6d684"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iteration: 0, Loss: 3.1255974769592285\n",
            "Epoch: 0, Iteration: 100, Loss: 1.4144315719604492\n",
            "Epoch: 0, Iteration: 200, Loss: 0.8890809416770935\n",
            "Epoch: 0, Iteration: 300, Loss: 0.3105986714363098\n",
            "Epoch: 0, Iteration: 400, Loss: 1.0406700372695923\n",
            "Epoch: 0, Iteration: 500, Loss: 0.5258834958076477\n",
            "Epoch: 0, Iteration: 600, Loss: 0.18848632276058197\n",
            "Epoch: 0, Iteration: 700, Loss: 0.19386625289916992\n",
            "Epoch: 0, Iteration: 800, Loss: 0.26122918725013733\n",
            "Epoch: 0, Iteration: 900, Loss: 0.25111138820648193\n",
            "Epoch: 0, Iteration: 1000, Loss: 0.2983989417552948\n",
            "Epoch: 0, Iteration: 1100, Loss: 0.27889081835746765\n",
            "Epoch: 0, Iteration: 1200, Loss: 0.21425330638885498\n",
            "Epoch: 0, Iteration: 1300, Loss: 0.2454027682542801\n",
            "Epoch: 0, Iteration: 1400, Loss: 0.27069780230522156\n",
            "Epoch: 0, Iteration: 1500, Loss: 0.07453617453575134\n",
            "Epoch: 0, Iteration: 1600, Loss: 0.08860261738300323\n",
            "Epoch: 0, Iteration: 1700, Loss: 0.23084421455860138\n",
            "Epoch: 0, Iteration: 1800, Loss: 0.05512172356247902\n",
            "Epoch: 0, Iteration: 1900, Loss: 0.07342475652694702\n",
            "Epoch: 0, Iteration: 2000, Loss: 0.042745862156152725\n",
            "Epoch: 0, Iteration: 2100, Loss: 0.09895267337560654\n",
            "Epoch: 0, Iteration: 2200, Loss: 0.007701886352151632\n",
            "Epoch: 0, Iteration: 2300, Loss: 0.13423781096935272\n",
            "Epoch: 0, Iteration: 2400, Loss: 0.008893058635294437\n",
            "Epoch: 0, Iteration: 2500, Loss: 0.06601112335920334\n",
            "Epoch: 0, Iteration: 2600, Loss: 0.1939583271741867\n",
            "Epoch: 0, Iteration: 2700, Loss: 0.056384749710559845\n",
            "Epoch: 0, Iteration: 2800, Loss: 0.00984729453921318\n",
            "Epoch: 0, Iteration: 2900, Loss: 0.023248298093676567\n",
            "Epoch: 0, Iteration: 3000, Loss: 0.0644034594297409\n",
            "Epoch: 0, Iteration: 3100, Loss: 0.117808036506176\n",
            "Epoch: 0, Iteration: 3200, Loss: 0.016002232208848\n",
            "Epoch: 0, Iteration: 3300, Loss: 0.0649813711643219\n",
            "Epoch: 0, Iteration: 3400, Loss: 0.007751241326332092\n",
            "Epoch: 0, Iteration: 3500, Loss: 0.01991899684071541\n",
            "Epoch: 0, Iteration: 3600, Loss: 0.13428042829036713\n",
            "Epoch: 0, Iteration: 3700, Loss: 0.005775440484285355\n",
            "Epoch: 0, Iteration: 3800, Loss: 0.056614894419908524\n",
            "Epoch: 0, Iteration: 3900, Loss: 0.1496991664171219\n",
            "Epoch: 0, Iteration: 4000, Loss: 0.03498651832342148\n",
            "Epoch: 0, Iteration: 4100, Loss: 0.09517305344343185\n",
            "Epoch: 0, Iteration: 4200, Loss: 0.008627934381365776\n",
            "Epoch: 0, Iteration: 4300, Loss: 0.030161211267113686\n",
            "Epoch: 0, Iteration: 4400, Loss: 0.02359134703874588\n",
            "Epoch: 0, Iteration: 4500, Loss: 0.03897462040185928\n",
            "Epoch: 0, Iteration: 4600, Loss: 0.00437849061563611\n",
            "Epoch: 0, Iteration: 4700, Loss: 0.03279838338494301\n",
            "Epoch: 0, Iteration: 4800, Loss: 0.04462450370192528\n",
            "Epoch: 0, Iteration: 4900, Loss: 0.00468752346932888\n",
            "Epoch: 0, Iteration: 5000, Loss: 0.023993387818336487\n",
            "Epoch: 0, Iteration: 5100, Loss: 0.007382999639958143\n",
            "Epoch: 0, Iteration: 5200, Loss: 0.001676843618042767\n",
            "Epoch: 0, Iteration: 5300, Loss: 0.009165629744529724\n",
            "Epoch: 0, Iteration: 5400, Loss: 0.126924529671669\n",
            "Epoch: 0, Iteration: 5500, Loss: 0.049766041338443756\n",
            "Epoch: 0, Iteration: 5600, Loss: 0.0032501695677638054\n",
            "Epoch: 0, Iteration: 5700, Loss: 0.00980684719979763\n",
            "Epoch: 0, Iteration: 5800, Loss: 0.0013919648481532931\n",
            "Epoch: 0, Iteration: 5900, Loss: 0.004204718396067619\n",
            "Epoch: 0, Iteration: 6000, Loss: 0.03889281675219536\n",
            "Epoch: 0, Iteration: 6100, Loss: 0.0030012251809239388\n",
            "Epoch: 0, Iteration: 6200, Loss: 0.022884029895067215\n",
            "Epoch: 0, Iteration: 6300, Loss: 0.00599621282890439\n",
            "Epoch: 0, Iteration: 6400, Loss: 0.003391507314518094\n",
            "Epoch: 0, Iteration: 6500, Loss: 0.011620806530117989\n",
            "Epoch: 0, Iteration: 6600, Loss: 0.0408911257982254\n",
            "Epoch: 0, Iteration: 6700, Loss: 0.011225569061934948\n",
            "Epoch: 0, Iteration: 6800, Loss: 0.0022339308634400368\n",
            "Epoch: 0, Iteration: 6900, Loss: 0.0021208925172686577\n",
            "Epoch: 0, Iteration: 7000, Loss: 0.007109618745744228\n",
            "Epoch: 0, Iteration: 7100, Loss: 0.004053141921758652\n",
            "Epoch: 0, Iteration: 7200, Loss: 0.029668016359210014\n",
            "Epoch: 0, Iteration: 7300, Loss: 0.0014503407292068005\n",
            "Epoch: 0, Iteration: 7400, Loss: 0.01032400131225586\n",
            "Epoch: 0, Iteration: 7500, Loss: 0.013888808898627758\n",
            "Epoch: 0, Iteration: 7600, Loss: 0.040730882436037064\n",
            "Epoch: 0, Iteration: 7700, Loss: 0.003177504288032651\n",
            "Epoch: 0, Iteration: 7800, Loss: 0.013602260500192642\n",
            "Epoch: 0, Iteration: 7900, Loss: 0.0033279669005423784\n",
            "Epoch: 0, Iteration: 8000, Loss: 0.0020290883257985115\n",
            "Epoch: 0, Iteration: 8100, Loss: 0.0010547628626227379\n",
            "Epoch: 0, Iteration: 8200, Loss: 0.0262062456458807\n",
            "Epoch: 0, Iteration: 8300, Loss: 0.002371270442381501\n",
            "Epoch: 0, Iteration: 8400, Loss: 0.0010698449332267046\n",
            "Epoch: 0, Iteration: 8500, Loss: 0.0006635787431150675\n",
            "Epoch: 0, Iteration: 8600, Loss: 0.006101875100284815\n",
            "Epoch: 0, Iteration: 8700, Loss: 0.0015894719399511814\n",
            "Epoch: 0, Iteration: 8800, Loss: 0.028793811798095703\n",
            "Epoch: 0, Iteration: 8900, Loss: 0.024625904858112335\n",
            "Epoch: 0, Iteration: 9000, Loss: 0.0022673141211271286\n",
            "Epoch: 0, Iteration: 9100, Loss: 0.0017760682385414839\n",
            "Epoch: 0, Iteration: 9200, Loss: 0.0010010446421802044\n",
            "Epoch: 0, Iteration: 9300, Loss: 0.0017497785156592727\n",
            "Epoch: 0, Iteration: 9400, Loss: 0.01387939415872097\n",
            "Epoch: 0, Iteration: 9500, Loss: 0.0017748319078236818\n",
            "Epoch: 0, Iteration: 9600, Loss: 0.0005358236958272755\n",
            "Epoch: 0, Iteration: 9700, Loss: 0.0018607309320941567\n",
            "Epoch: 0, Iteration: 9800, Loss: 0.002433889079838991\n",
            "Epoch: 0, Iteration: 9900, Loss: 0.009396618232131004\n",
            "Epoch: 0, Iteration: 10000, Loss: 0.0011676520807668567\n",
            "Epoch: 0, Iteration: 10100, Loss: 0.018554706126451492\n",
            "Epoch: 0, Iteration: 10200, Loss: 0.0027031966019421816\n",
            "Epoch: 0, Iteration: 10300, Loss: 0.0011685634963214397\n",
            "Epoch: 0, Iteration: 10400, Loss: 0.008014068938791752\n",
            "Epoch: 0, Iteration: 10500, Loss: 0.002230288228020072\n",
            "Epoch: 0, Iteration: 10600, Loss: 0.020852940157055855\n",
            "Epoch: 0, Iteration: 10700, Loss: 0.0020636427216231823\n",
            "Epoch: 0, Iteration: 10800, Loss: 0.05214105173945427\n",
            "Epoch: 0, Iteration: 10900, Loss: 0.001721432781778276\n",
            "Epoch: 0, Iteration: 11000, Loss: 0.0005174011457711458\n",
            "Epoch: 0, Iteration: 11100, Loss: 0.012321650981903076\n",
            "Epoch: 0, Iteration: 11200, Loss: 0.0006072981050238013\n",
            "Epoch: 0, Iteration: 11300, Loss: 0.03391131013631821\n",
            "Epoch: 0, Iteration: 11400, Loss: 0.00032522910623811185\n",
            "Epoch: 0, Iteration: 11500, Loss: 0.00279224943369627\n",
            "Epoch: 0, Iteration: 11600, Loss: 0.0005048299790360034\n",
            "Epoch: 0, Iteration: 11700, Loss: 0.002140570664778352\n",
            "Epoch: 0, Iteration: 11800, Loss: 0.036751434206962585\n",
            "Epoch: 0, Iteration: 11900, Loss: 0.00023372170107904822\n",
            "Epoch: 0, Iteration: 12000, Loss: 0.06389118731021881\n",
            "Epoch: 0, Iteration: 12100, Loss: 0.000315825454890728\n",
            "Epoch: 0, Iteration: 12200, Loss: 0.0007587988511659205\n",
            "Epoch: 0, Iteration: 12300, Loss: 0.0036877854727208614\n",
            "Epoch: 0, Iteration: 12400, Loss: 0.0002627251378726214\n",
            "Epoch: 0, Iteration: 12500, Loss: 0.002525026211515069\n",
            "Epoch: 0, Iteration: 12600, Loss: 0.033291373401880264\n",
            "Epoch: 0, Iteration: 12700, Loss: 0.04118720442056656\n",
            "Epoch: 0, Iteration: 12800, Loss: 0.007978533394634724\n",
            "Epoch: 0, Iteration: 12900, Loss: 0.00029584442381747067\n",
            "Epoch: 0, Iteration: 13000, Loss: 0.06545927375555038\n",
            "Epoch: 0, Iteration: 13100, Loss: 0.0008978188270702958\n",
            "Epoch: 0, Iteration: 13200, Loss: 0.011553419753909111\n",
            "Epoch: 0, Iteration: 13300, Loss: 0.00037624782999046147\n",
            "Epoch: 0, Iteration: 13400, Loss: 0.00739089073613286\n",
            "Epoch: 0, Iteration: 13500, Loss: 0.003490969305858016\n",
            "Epoch: 0, Iteration: 13600, Loss: 0.00022067490499466658\n",
            "Epoch: 0, Iteration: 13700, Loss: 0.000935817661229521\n",
            "Epoch: 0, Iteration: 13800, Loss: 0.00028712311177514493\n",
            "Epoch: 0, Iteration: 13900, Loss: 0.0018734188051894307\n",
            "Epoch: 0, Iteration: 14000, Loss: 0.0004987178253941238\n",
            "Epoch: 0, Iteration: 14100, Loss: 6.626942922594026e-05\n",
            "Epoch: 0, Iteration: 14200, Loss: 0.0013545958790928125\n",
            "Epoch: 0, Iteration: 14300, Loss: 0.0026342093478888273\n",
            "Epoch: 0, Iteration: 14400, Loss: 0.00040059498860500753\n",
            "Epoch: 0, Iteration: 14500, Loss: 0.0023044217377901077\n",
            "Epoch: 0, Iteration: 14600, Loss: 0.00043730586185120046\n",
            "Epoch: 0, Iteration: 14700, Loss: 0.0003367920871824026\n",
            "Epoch: 0, Iteration: 14800, Loss: 0.0003446001501288265\n",
            "Epoch: 0, Iteration: 14900, Loss: 0.0028473243582993746\n",
            "Epoch: 0, Iteration: 15000, Loss: 0.0002823439135681838\n",
            "Epoch: 0, Iteration: 15100, Loss: 0.0007432076963596046\n",
            "Epoch: 0, Iteration: 15200, Loss: 0.00020240360754542053\n",
            "Epoch: 0, Iteration: 15300, Loss: 0.01644207164645195\n",
            "Epoch: 0, Iteration: 15400, Loss: 0.003857725765556097\n",
            "Epoch: 0, Iteration: 15500, Loss: 0.00030796503415331244\n",
            "Epoch: 0, Iteration: 15600, Loss: 0.0069144172593951225\n",
            "Epoch: 0, Iteration: 15700, Loss: 0.006277453154325485\n",
            "Epoch: 0, Iteration: 15800, Loss: 0.02156154438853264\n",
            "Epoch: 0, Iteration: 15900, Loss: 0.004229458048939705\n",
            "Epoch: 0, Iteration: 16000, Loss: 0.005083788186311722\n",
            "Epoch: 0, Iteration: 16100, Loss: 0.0001656308741075918\n",
            "Epoch: 0, Iteration: 16200, Loss: 0.00046024579205550253\n",
            "Epoch: 0, Iteration: 16300, Loss: 0.00013536072219721973\n",
            "Epoch: 0, Iteration: 16400, Loss: 0.0018393353093415499\n",
            "Epoch: 0, Iteration: 16500, Loss: 0.001918769790790975\n",
            "Epoch: 0, Iteration: 16600, Loss: 3.4919969039037824e-05\n",
            "Epoch: 0, Iteration: 16700, Loss: 0.00016630905156489462\n",
            "Epoch: 0, Iteration: 16800, Loss: 0.0006366793531924486\n",
            "Epoch: 0, Iteration: 16900, Loss: 0.0002587985363788903\n",
            "Epoch: 0, Iteration: 17000, Loss: 0.004237432964146137\n",
            "Epoch: 0, Iteration: 17100, Loss: 0.00015740956587251276\n",
            "Epoch: 0, Iteration: 17200, Loss: 0.0003029771614819765\n",
            "Epoch: 0, Iteration: 17300, Loss: 0.0005816395860165358\n",
            "Epoch: 0, Iteration: 17400, Loss: 0.0003581697237677872\n",
            "Epoch: 0, Iteration: 17500, Loss: 0.00036387614090926945\n",
            "Epoch: 0, Iteration: 17600, Loss: 0.004386563319712877\n",
            "Epoch: 0, Iteration: 17700, Loss: 0.0003769726608879864\n",
            "Epoch: 0, Iteration: 17800, Loss: 0.0008222098113037646\n",
            "Epoch: 0, Iteration: 17900, Loss: 0.0004981074016541243\n",
            "Epoch: 0, Iteration: 18000, Loss: 0.0010139038786292076\n",
            "Epoch: 0, Iteration: 18100, Loss: 0.00010428736277390271\n",
            "Epoch: 0, Iteration: 18200, Loss: 0.00019114193855784833\n",
            "Epoch: 0, Iteration: 18300, Loss: 0.0005650038947351277\n",
            "Epoch: 0, Iteration: 18400, Loss: 0.00034048291854560375\n",
            "Epoch: 0, Iteration: 18500, Loss: 0.0001721538428682834\n",
            "Epoch: 0, Iteration: 18600, Loss: 0.012064511887729168\n",
            "Epoch: 0, Iteration: 18700, Loss: 0.00027223414508625865\n",
            "Epoch: 0, Iteration: 18800, Loss: 0.0006069880328141153\n",
            "Epoch: 0, Iteration: 18900, Loss: 0.0009263347019441426\n",
            "Epoch: 0, Iteration: 19000, Loss: 0.0001524556428194046\n",
            "Epoch: 0, Iteration: 19100, Loss: 0.0023676364216953516\n",
            "Epoch: 0, Iteration: 19200, Loss: 0.0008259909809567034\n",
            "Epoch: 0, Iteration: 19300, Loss: 0.00019912740390282124\n",
            "Epoch: 0, Iteration: 19400, Loss: 0.00017119206313509494\n",
            "Epoch: 0, Iteration: 19500, Loss: 0.00028254493372514844\n",
            "Epoch: 0, Iteration: 19600, Loss: 0.0001638659305172041\n",
            "Epoch: 0, Iteration: 19700, Loss: 0.0008429266745224595\n",
            "Epoch: 0, Iteration: 19800, Loss: 0.0008807099657133222\n",
            "Epoch: 0, Iteration: 19900, Loss: 0.00023494107881560922\n",
            "Epoch: 0, Iteration: 20000, Loss: 4.063431697431952e-05\n",
            "Epoch: 0, Iteration: 20100, Loss: 0.0005632651736959815\n",
            "Epoch: 0, Iteration: 20200, Loss: 0.0003631055005826056\n",
            "Epoch: 0, Iteration: 20300, Loss: 6.997241143835708e-05\n",
            "Epoch: 0, Iteration: 20400, Loss: 0.0001306347403442487\n",
            "Epoch: 0, Iteration: 20500, Loss: 7.323233148781583e-05\n",
            "Epoch: 0, Iteration: 20600, Loss: 0.00018834308139048517\n",
            "Epoch: 0, Iteration: 20700, Loss: 9.049003710970283e-05\n",
            "Epoch: 0, Iteration: 20800, Loss: 0.0001380230678478256\n",
            "Epoch: 0, Iteration: 20900, Loss: 0.00032119196839630604\n",
            "Epoch: 0, Iteration: 21000, Loss: 0.0007754523539915681\n",
            "Epoch: 0, Iteration: 21100, Loss: 0.0004157344519626349\n",
            "Epoch: 0, Iteration: 21200, Loss: 0.00010567230492597446\n",
            "Epoch: 0, Iteration: 21300, Loss: 7.071728759910911e-05\n",
            "Epoch: 0, Iteration: 21400, Loss: 0.000786849413998425\n",
            "Epoch: 0, Iteration: 21500, Loss: 0.00021604547509923577\n",
            "Epoch: 0, Iteration: 21600, Loss: 0.00016402073379140347\n",
            "Epoch: 0, Iteration: 21700, Loss: 3.426375042181462e-05\n",
            "Epoch: 0, Iteration: 21800, Loss: 0.0001143582267104648\n",
            "Epoch: 0, Iteration: 21900, Loss: 2.961379686894361e-05\n",
            "Epoch: 0, Iteration: 22000, Loss: 4.850719415117055e-05\n",
            "Epoch: 0, Iteration: 22100, Loss: 0.02289930172264576\n",
            "Epoch: 0, Iteration: 22200, Loss: 0.004112055990844965\n",
            "Epoch: 0, Iteration: 22300, Loss: 0.0012601721100509167\n",
            "Epoch: 0, Iteration: 22400, Loss: 0.0001509555586380884\n",
            "Epoch: 0, Iteration: 22500, Loss: 4.621758489520289e-05\n",
            "Epoch: 0, Iteration: 22600, Loss: 0.0011746311793103814\n",
            "Epoch: 0, Iteration: 22700, Loss: 0.012007608078420162\n",
            "Epoch: 0, Iteration: 22800, Loss: 0.0002782945230137557\n",
            "Epoch: 0, Iteration: 22900, Loss: 0.0007091376464813948\n",
            "Epoch: 0, Iteration: 23000, Loss: 0.00014895219646859914\n",
            "Epoch: 0, Iteration: 23100, Loss: 3.95709830627311e-05\n",
            "Epoch: 0, Iteration: 23200, Loss: 8.452913607470691e-05\n",
            "Epoch: 0, Iteration: 23300, Loss: 0.008375531062483788\n",
            "Epoch: 0, Iteration: 23400, Loss: 0.000539524364285171\n",
            "Epoch: 0, Iteration: 23500, Loss: 0.00010217088129138574\n",
            "Epoch: 0, Iteration: 23600, Loss: 0.019702773541212082\n",
            "Epoch: 0, Iteration: 23700, Loss: 0.00020789327390957624\n",
            "Epoch: 0, Iteration: 23800, Loss: 0.0004268863413017243\n",
            "Epoch: 0, Iteration: 23900, Loss: 0.00026841426733881235\n",
            "Epoch: 0, Iteration: 24000, Loss: 0.0014488211600109935\n",
            "Epoch: 0, Iteration: 24100, Loss: 5.7724366342881694e-05\n",
            "Epoch: 0, Iteration: 24200, Loss: 0.00010961842053802684\n",
            "Epoch: 0, Iteration: 24300, Loss: 8.991626964416355e-05\n",
            "Epoch: 0, Iteration: 24400, Loss: 0.004175362642854452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=50, num_return_sequences=1, temperature=1.0, top_k=50, top_p=0.95):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "    # Generate text\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=num_return_sequences,\n",
        "            temperature=1.0,  # higher value: more random, smaller value: more deterministic\n",
        "            top_k=50,  # truncates to only consider top k words for next token\n",
        "            top_p=0.95,  # nucleus sampling: limits next token selection to subset of vocab\n",
        "            do_sample=True,  # Enable sampling\n",
        "            num_beams=1  # Use single beam search. Increase if you want to use more beams.\n",
        "        )\n",
        "\n",
        "    # Decode and print the text\n",
        "    generated_text = [tokenizer.decode(o, skip_special_tokens=True) for o in output]\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "9DlSQjt3uD-b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "#prompt = \"Tumefanya mabadiliko\"\n",
        "#predictions = generate_text(prompt, max_length=100, num_return_sequences=3)"
      ],
      "metadata": {
        "id": "vcOySC5ouO59"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = generate_text(\n",
        "    \"tumefanya mabadiliko\",\n",
        "    max_length=100,\n",
        "    num_return_sequences=3,\n",
        "    temperature=2.0,\n",
        "    top_k=40,\n",
        "    top_p=0.85\n",
        ")"
      ],
      "metadata": {
        "id": "Pl0PN8NMvgOu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the generated texts\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Generated Text {i + 1}: {pred}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEfEZAydu6ny",
        "outputId": "8aae438a-8dd4-45eb-d7fd-973657505c42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 1: tumefanya mabadiliko\n",
            "\n",
            "Generated Text 2: tumefanya mabadiliko\n",
            "\n",
            "Generated Text 3: tumefanya mabadiliko\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "oQ6O9urBvAf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model saving\n",
        "#model.save_pretrained(\"path_to_save_model\")\n",
        "#tokenizer.save_pretrained(\"path_to_save_model\")"
      ],
      "metadata": {
        "id": "0Y_bM_WLjQQG"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}