{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instalations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import whisper\n",
        "from pytube import YouTube\n",
        "import gradio as gr\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def yt_audio(video_url):\n",
        "\tyt = YouTube(str(video_url))\n",
        "\tvideo = yt.streams.filter(only_audio=True).first()\n",
        "\tdestination = 'Files/'\n",
        "\taudio_file = video.download(output_path=destination)\n",
        "\tbase, ext = os.path.splitext(audio_file)\n",
        "\tfile_path = base + '.mp3'\n",
        "\tos.rename(audio_file, file_path)\n",
        "\t\n",
        "\treturn str(file_path)\t\t\t\t\t\t\t\t\t# Returns the path of the downloaded audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_file = yt_audio('https://www.youtube.com/watch?v=9V3L8R5DlNg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [05:40<00:00, 1.42MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model('small')\n",
        "\n",
        "# There are other models available\n",
        "\n",
        "# 1. tiny, 2. base, 3. small, 4. medium, 5. large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/olang/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Twitter says that it has nearly 240 million monetizable daily active users. Millions of those accounts though aren't real. They're bots, spam and fake accounts. And that's something both Twitter and Elon Musk accept. But what they don't agree on is how many accounts are fake, or even what a bot is. Depending on how you define bot, you could have anywhere from less than 1% to 20%. It's a debate that's turned into a $44 billion question as Elon Musk attempts to back out of a deal to buy Twitter. So how many bots are there on Twitter? First of all, Twitter claims that less than 5% of all of its daily active users are bots. Elon Musk though says that figure is nonsense. What do you think it is? What's the, I mean, it's not 5%, what is it? I think it's some number that is probably at least four or five times that number. This is why Elon Musk, at least he claims, is backing out of the deal. He's even accused Twitter of fraud. The center of the disagreement comes down to a definition. What actually is a bot? Michael Carney is founder of Twitter Bot or Not. You could have an account that just tweets out gibberish based on a computer algorithm. But then one time, if that account is tweeted from someone's cell phone and a real person making their honest comment on the world, is that a bot account or not? So it's not a static thing that exists. Without an agreed on definition, Elon Musk had a go at trying to estimate the number anyway. In his countersuit, his team claimed to use a tool called Botometer and concluded that 33% of all Twitter accounts were bots. The problem is Botometer doesn't actually say whether an account is a bot or not, just a score out of five. Five being likely to be a bot, zero unlikely. So where did Elon Musk draw that line? So how to choose this threshold is key to the answer of how many bots are there on the platform. It's not clear what Elon Musk's team did, right? So to me, they can choose any special they want. Twitter's bot claims, though, are also, at the very least, questionable. This is Clayton Davis, one of the researchers who created Botometer. Twitter has slightly conflicting priorities. On one hand, they care about credibility, but they also care about having high user numbers, right? That charge was backed up by Twitter whistleblower and former head of security, Peter Zatko, who claimed that Twitter execs are financially incentivized to count bots as people. This all comes down to how Twitter actually counts its bots, and it's way less techy than you might imagine. The chief executive, Parig Agrawal, described in a tweet how they do this. Our estimate is based on multiple human reviews, he said. Elon Musk says that is totally unscientific. And yet the creator and maintainer of Botometer, the tool that Elon Musk is using, thinks that Twitter's methodology actually isn't that bad. If I were the people in Twitter, I would probably do something similar, right? It's just still, to me, how they define those things, it's not clear. If they really want to do this, they can sit together so we can say, oh, can we agree on this, this account is bot, this account is human. But Twitter and Elon Musk aren't sitting down together. They simply cannot agree how many bots Twitter has. And that's the fundamental problem, perhaps no one can.\n"
          ]
        }
      ],
      "source": [
        "print(trascribe(sample_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trascribe(video_url):\n",
        "    # generate file path\n",
        "    file_path = yt_audio(video_url)\n",
        "\n",
        "    # Transcribe audio file\n",
        "    trascription_dict = model.transcribe(file_path)\n",
        "    text = trascription_dict['text']\n",
        "    language = trascription_dict['language']\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7ff07878daf0>, 'http://127.0.0.1:7861/', None)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_app = gr.Interface(\n",
        "    title = \"Youtube video trascription using OpenAI's Whisper 'Small' model\",\n",
        "    fn = trascribe,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Youtube Video URL\"),\n",
        "    outputs=gr.Textbox(placeholder=\"Transcritpion.\", interactive=True),\n",
        ")\n",
        "\n",
        "demo_app.launch(share=True,)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMih262ycIvTe3IKrZhKzyp",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
