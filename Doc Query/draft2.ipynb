{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"That restaurant was not as good as the last movie I watched.\",\n",
    "    \"I'm selling a used car in good condition\",\n",
    "    \"Food was okay, the rest so so\",\n",
    "    \"I love cats, but don't really like hyenas\",\n",
    "    \"On the road, you must be careful\",\n",
    "]\n",
    "\n",
    "vectors = [\n",
    "  # tokenize the document, return it as PyTorch tensors (vectors),\n",
    "  # and pass it onto the model\n",
    "  model(**tokenizer(document, return_tensors='pt'))[0].detach().squeeze()\n",
    "  for document in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([15, 768]),\n",
       " torch.Size([12, 768]),\n",
       " torch.Size([10, 768]),\n",
       " torch.Size([15, 768]),\n",
       " torch.Size([10, 768])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.size() for v in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "averaged_vectors = [torch.mean(vector, dim=0) for vector in vectors]\n",
    "\n",
    "[v.size() for v in averaged_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(document: str) -> torch.Tensor:\n",
    "    tokens = tokenizer(document, return_tensors='pt')       # tokenize usign the tokenizer\n",
    "    vector = model(**tokens)[0].detach().squeeze()      # pass the tokens to the model to get the vector\n",
    "    return torch.mean(vector, dim=0)                # average the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# convert the PyTorch tensors to NumPy arrays\n",
    "\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768)) # create an index\n",
    "\n",
    "index.add_with_ids(\n",
    "    np.array([t.numpy() for t in averaged_vectors]),\n",
    "    np.array(range(0, len(documents)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, k=1):\n",
    "    encoded_query = encode(query).unsqueeze(dim=0).numpy()\n",
    "    top_k = index.search(encoded_query, k)\n",
    "    scores = top_k[0][0]\n",
    "    results = [documents[_id] for _id in top_k[1][0]]\n",
    "    return list(zip(results, scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm selling a used car in good condition\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "search(documents[1], k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
