{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying Names.ipynb",
      "provenance": [],
      "mount_file_id": "1SiKWy0Ws-JqLw9lCt0k2ak6zyc7bhzWO",
      "authorship_tag": "ABX9TyNWsYxLd5spf9ebPvk52m3B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoeOlang/NLP/blob/main/Pytorch/Classifying_Names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YovFR-6u2OhJ"
      },
      "source": [
        "Classifying Names With a Character Level RNN (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6cRQd8u8QJE",
        "outputId": "c1e49b41-6971-4d27-f358-f6564f0be184"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP/Basics/RNN Name Classification"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NLP/Basics/RNN Name Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PipJrNu8fpd",
        "outputId": "86d4f945-afb9-4d95-88d5-5bc5af8a8ebf"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Classifying Names.ipynb'   eng-fra.txt   \u001b[0m\u001b[01;34mnames\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHtGaT5r0Vv5"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgKVuZ1j0Ymj",
        "outputId": "c7e9a7f1-7c81-45fd-9310-9d2b022ef108"
      },
      "source": [
        "def findfiles(path): return glob.glob(path)\n",
        "\n",
        "print(findfiles('names/*.txt'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['names/French.txt', 'names/Dutch.txt', 'names/Italian.txt', 'names/Vietnamese.txt', 'names/Korean.txt', 'names/Portuguese.txt', 'names/German.txt', 'names/Chinese.txt', 'names/English.txt', 'names/Japanese.txt', 'names/Greek.txt', 'names/Polish.txt', 'names/Russian.txt', 'names/Irish.txt', 'names/Czech.txt', 'names/Scottish.txt', 'names/Arabic.txt', 'names/Spanish.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moApey6J3jTZ",
        "outputId": "1b0ceb46-df95-4c70-e88c-d411eccdd6fd"
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Unicode to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build a cateogry lines dict, a list of names per lang.\n",
        "category_lines = {}\n",
        "all_categories =[]\n",
        "\n",
        "# read file and split into lines\n",
        "def readlines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findfiles('names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readlines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slusarski\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwICQBGN9vrZ",
        "outputId": "24197a92-1263-4061-8a4a-3729a09833c4"
      },
      "source": [
        "print(category_lines['Italian'][:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNiLCqYd-ZOa",
        "outputId": "d5f82787-1ba0-416a-e37f-ac12a5586d4f"
      },
      "source": [
        "import torch\n",
        "\n",
        "# find letter index from all_letters >> ONE-HOT-ENC\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('J'))\n",
        "\n",
        "print(letterToTensor('Jones').size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "torch.Size([1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCP3uP8iFkqc"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HGHivLkJB8t"
      },
      "source": [
        "input = letterToTensor('A')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WkhBhGrJ1OZ",
        "outputId": "2a0626e0-2612-481a-df73-a80f3c7b3d87"
      },
      "source": [
        "input = lineToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.8355, -2.8521, -2.9204, -2.8689, -2.9517, -3.0252, -2.8649, -2.8294,\n",
            "         -2.8673, -2.8910, -2.8454, -2.8438, -3.0373, -2.9247, -2.8410, -2.9046,\n",
            "         -2.9252, -2.8307]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZhGbgjXKfhE",
        "outputId": "4ee198c2-0063-48f7-a153-265e887eb8d5"
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(output))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Chinese', 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1IzGMdgL-XS",
        "outputId": "30a7c026-1748-4cd2-b2bc-cedaafdcded5"
      },
      "source": [
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    line = randomChoice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype = torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category = ', category, '/line =', line)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "category =  Polish /line = Salomon\n",
            "category =  English /line = Carmichael\n",
            "category =  Irish /line = Clark\n",
            "category =  Russian /line = Pohmelkin\n",
            "category =  Czech /line = Kacirek\n",
            "category =  Japanese /line = Enomoto\n",
            "category =  Vietnamese /line = Thao\n",
            "category =  Japanese /line = Hasekura\n",
            "category =  Chinese /line = Rong\n",
            "category =  Irish /line = John\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}